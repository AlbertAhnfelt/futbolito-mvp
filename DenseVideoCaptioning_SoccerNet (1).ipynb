{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "-aS4imbQWdU9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aS4imbQWdU9",
        "outputId": "0807207c-f1cf-4d4a-f4a5-c129bf7d0ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SoccerNet\n",
            "  Downloading SoccerNet-0.1.62-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting Linformer\n",
            "  Downloading linformer-0.2.3-py3-none-any.whl.metadata (602 bytes)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from SoccerNet) (4.67.1)\n",
            "Collecting scikit-video (from SoccerNet)\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from SoccerNet) (3.10.0)\n",
            "Collecting google-measurement-protocol (from SoccerNet)\n",
            "  Downloading google_measurement_protocol-1.1.0-py2.py3-none-any.whl.metadata (845 bytes)\n",
            "Collecting pycocoevalcap (from SoccerNet)\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.12/dist-packages (from SoccerNet) (0.36.0)\n",
            "Collecting boto3 (from SoccerNet)\n",
            "  Downloading boto3-1.40.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Collecting botocore<1.41.0,>=1.40.64 (from boto3->SoccerNet)\n",
            "  Downloading botocore-1.40.64-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->SoccerNet)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->SoccerNet)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: requests<3.0a0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from google-measurement-protocol->SoccerNet) (2.32.4)\n",
            "Collecting prices>=1.0.0 (from google-measurement-protocol->SoccerNet)\n",
            "  Downloading prices-1.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[cli]->SoccerNet) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[cli]->SoccerNet) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub[cli]->SoccerNet) (1.2.0)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli]->SoccerNet)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli]->SoccerNet)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]->SoccerNet) (3.0.52)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->SoccerNet) (2.9.0.post0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from pycocoevalcap->SoccerNet) (2.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from scikit-video->SoccerNet) (1.16.3)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.64->boto3->SoccerNet) (2.5.0)\n",
            "Requirement already satisfied: babel>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from prices>=1.0.0->google-measurement-protocol->SoccerNet) (2.17.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->SoccerNet) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2025.10.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]->SoccerNet) (0.2.14)\n",
            "Downloading SoccerNet-0.1.62-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linformer-0.2.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading boto3-1.40.64-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_measurement_protocol-1.1.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.40.64-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading prices-1.1.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: prices, pfzy, jmespath, scikit-video, pycocoevalcap, InquirerPy, google-measurement-protocol, botocore, s3transfer, Linformer, boto3, SoccerNet\n",
            "Successfully installed InquirerPy-0.3.4 Linformer-0.2.3 SoccerNet-0.1.62 boto3-1.40.64 botocore-1.40.64 google-measurement-protocol-1.1.0 jmespath-1.0.1 pfzy-0.3.4 prices-1.1.1 pycocoevalcap-1.2 s3transfer-0.14.0 scikit-video-1.1.11\n"
          ]
        }
      ],
      "source": [
        "!pip install SoccerNet torch torchvision Linformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a9136c43",
      "metadata": {
        "id": "a9136c43"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import os, json, re\n",
        "import numpy as np\n",
        "from linformer import Linformer\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from SoccerNet.utils import getListGames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Jan9-tz_65ta",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jan9-tz_65ta",
        "outputId": "7855afa3-26d8-4349-d6de-385d1ba57028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QCOXFrvtXdAD",
      "metadata": {
        "id": "QCOXFrvtXdAD"
      },
      "source": [
        "###Dataset Organization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69b2869c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69b2869c",
        "outputId": "3d917c18-1de8-45ab-b2b7-a3dbc59329dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shots on target by away at 2 - 36:40\n",
            "Direct free-kick by home at 1 - 37:43\n"
          ]
        }
      ],
      "source": [
        "LOCAL_DIR = \"/content/drive/MyDrive/SoccerNetData\"\n",
        "\n",
        "class SoccerNetCaptionDataset(Dataset):\n",
        "    def __init__(self, local_dir, split=\"train\", feature_type=\"1_ResNET_TF2.npy\", mode=\"random\"):\n",
        "        self.local_dir = local_dir\n",
        "        self.feature_type = feature_type\n",
        "        self.games = getListGames(split=split)\n",
        "        self.mode = mode  # \"random\" or \"concat\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.games)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        game = self.games[idx]\n",
        "        game_dir = os.path.join(self.local_dir, game)\n",
        "        label_path = os.path.join(game_dir, \"Labels-v2.json\")\n",
        "        feature_path = os.path.join(game_dir, self.feature_type)\n",
        "\n",
        "        if (not os.path.exists(feature_path)) or (not os.path.exists(label_path)):\n",
        "            dummy_feat = torch.zeros((32, 2048), dtype=torch.float32)\n",
        "            return dummy_feat, \"No event\"\n",
        "\n",
        "        features = np.load(feature_path)\n",
        "        features = torch.from_numpy(features).float()\n",
        "\n",
        "        caption = \"No event\"\n",
        "        try:\n",
        "            with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            if \"annotations\" in data and len(data[\"annotations\"]) > 0:\n",
        "                if self.mode == \"random\":\n",
        "                    ann = random.choice(data[\"annotations\"])\n",
        "                    event_label = ann.get(\"label\", \"Unknown\")\n",
        "                    team = ann.get(\"team\", None)\n",
        "                    minute = ann.get(\"gameTime\", None)\n",
        "                    caption = f\"{event_label} by {team}\" if team else event_label\n",
        "                    if minute:\n",
        "                        caption += f\" at {minute}\"\n",
        "\n",
        "                elif self.mode == \"concat\":\n",
        "                    events = []\n",
        "                    for ann in data[\"annotations\"][:5]:\n",
        "                        label = ann.get(\"label\", \"Unknown\")\n",
        "                        team = ann.get(\"team\", \"\")\n",
        "                        minute = ann.get(\"gameTime\", \"\")\n",
        "                        events.append(f\"{label} ({team}) at {minute}\")\n",
        "                    caption = \" ; \".join(events)\n",
        "        except Exception:\n",
        "            caption = \"No event\"\n",
        "\n",
        "        return features, caption\n",
        "\n",
        "train_dataset = SoccerNetCaptionDataset(LOCAL_DIR, split=\"train\", mode=\"random\")\n",
        "print(train_dataset[100][1])\n",
        "\n",
        "val_dataset = SoccerNetCaptionDataset(LOCAL_DIR, split=\"valid\", mode=\"random\")\n",
        "print(val_dataset[2][1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BXQdUYp5XtuT",
      "metadata": {
        "id": "BXQdUYp5XtuT"
      },
      "source": [
        "### Light Encoder (Just to have the good dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "781e2b84",
      "metadata": {
        "id": "781e2b84"
      },
      "outputs": [],
      "source": [
        "class SoccerNetEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512, pool_factor=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.pool_factor = pool_factor\n",
        "\n",
        "        self.temporal_gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
        "\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, T, 2048] ‚Üí video features\n",
        "        \"\"\"\n",
        "        x = self.proj(x)  # [B, T, H]\n",
        "\n",
        "        if x.size(1) > self.pool_factor:\n",
        "            x = x.transpose(1, 2)  # [B, H, T]\n",
        "            x = F.avg_pool1d(x, kernel_size=self.pool_factor, stride=self.pool_factor)\n",
        "            x = x.transpose(1, 2)  # [B, T//pool_factor, H]\n",
        "\n",
        "        x, _ = self.temporal_gru(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wNSiYCFFYEhu",
      "metadata": {
        "id": "wNSiYCFFYEhu"
      },
      "source": [
        "### Decoder (GRU + Linformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "hM1oY3txX9xw",
      "metadata": {
        "id": "hM1oY3txX9xw"
      },
      "outputs": [],
      "source": [
        "class CaptionDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim=512, vocab_size=10000, seq_len=64, n_heads=4, depth=3, linformer_k=64):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linformer = Linformer(\n",
        "            dim=hidden_dim,\n",
        "            seq_len=seq_len,\n",
        "            depth=depth,\n",
        "            heads=n_heads,\n",
        "            k=linformer_k\n",
        "        )\n",
        "\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Linear(hidden_dim, vocab_size)\n",
        "        )\n",
        "\n",
        "        self.max_seq_len = seq_len\n",
        "\n",
        "    def forward(self, features):\n",
        "        \"\"\"\n",
        "        features: [B, T, H]\n",
        "        \"\"\"\n",
        "        if features.size(1) > self.max_seq_len:\n",
        "            features = features[:, :self.max_seq_len, :]\n",
        "\n",
        "        attn_out = self.linformer(features)  # [B, T, H]\n",
        "\n",
        "        gru_out, _ = self.gru(attn_out)\n",
        "\n",
        "        logits = self.fc(gru_out)  # [B, T, vocab_size]\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5IJOzUa0Ycly",
      "metadata": {
        "id": "5IJOzUa0Ycly"
      },
      "source": [
        "### Model : Encoder+Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bDfd8YjrYbFf",
      "metadata": {
        "id": "bDfd8YjrYbFf"
      },
      "outputs": [],
      "source": [
        "class RealTimeVideoCaptionNet(nn.Module):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=512, vocab_size=10000, seq_len=64):\n",
        "        super().__init__()\n",
        "        self.encoder = SoccerNetEncoder(input_dim, hidden_dim)\n",
        "        self.decoder = CaptionDecoder(hidden_dim, vocab_size, seq_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: [B, T, 2048]\n",
        "        \"\"\"\n",
        "        encoded = self.encoder(x)\n",
        "        captions = self.decoder(encoded)\n",
        "        return captions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uAHjNhkPYtLE",
      "metadata": {
        "id": "uAHjNhkPYtLE"
      },
      "source": [
        "### Captions and Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "K0NZ9lunffcD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0NZ9lunffcD",
        "outputId": "a0ed04fa-4367-4e4b-d21b-bdd2d9270a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Number of games (train): 300\n",
            "üó£Ô∏è Extracted captions: 8000\n",
            "üîç Example: ['Kick-off by the away team', 'Ball out of play by the not applicable team', 'Throw-in by the away team', 'Ball out of play by the not applicable team', 'Corner by the away team']\n"
          ]
        }
      ],
      "source": [
        "def collect_captions_from_games(local_dir, games, max_files=None):\n",
        "    captions = []\n",
        "    n = 0\n",
        "    for game in games:\n",
        "        label_path = os.path.join(local_dir, game, \"Labels-v2.json\")\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(label_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            if \"annotations\" not in data or len(data[\"annotations\"]) == 0:\n",
        "                continue\n",
        "\n",
        "            for ann in data[\"annotations\"]:\n",
        "                lbl = ann.get(\"label\", \"\").strip()\n",
        "                team = ann.get(\"team\", None)\n",
        "                time = ann.get(\"gameTime\", None)\n",
        "                half = ann.get(\"half\", None)\n",
        "\n",
        "                if lbl:\n",
        "                    caption_parts = [lbl]\n",
        "                    if team:\n",
        "                        caption_parts.append(f\"by the {team} team\")\n",
        "                    \"\"\"\n",
        "                    if time:\n",
        "                        caption_parts.append(f\"at {time}\")\n",
        "                    if half:\n",
        "                        caption_parts.append(f\"in half {half}\")\n",
        "                    \"\"\"\n",
        "                    caption = \" \".join(caption_parts)\n",
        "                    captions.append(caption)\n",
        "                    n += 1\n",
        "\n",
        "                    if max_files is not None and n >= max_files:\n",
        "                        return captions\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return captions\n",
        "\n",
        "train_games = getListGames(split=\"train\")\n",
        "print(f\"üìÇ Number of games (train): {len(train_games)}\")\n",
        "\n",
        "captions_sample = collect_captions_from_games(LOCAL_DIR, train_games, max_files=8000)\n",
        "print(f\"üó£Ô∏è Extracted captions: {len(captions_sample)}\")\n",
        "print(\"üîç Example:\", captions_sample[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c_5uVGyZCsE",
      "metadata": {
        "id": "5c_5uVGyZCsE"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "grIN7db0ZAny",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grIN7db0ZAny",
        "outputId": "e55579d5-aafa-460c-bbda-06a31ea1cdfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßæ Total Vocabulary: 35 words\n",
            "üß© Examples : ['<PAD>', '<SOS>', '<EOS>', '<UNK>', 'by', 'the', 'team', 'away', 'home', 'ball', 'out', 'of', 'play', 'not', 'applicable', 'throw', 'in', 'kick', 'shots', 'target', 'foul', 'free', 'clearance', 'indirect', 'off', 'on', 'corner', 'substitution', 'direct', 'card', 'yellow', 'offside', 'goal', 'penalty']\n"
          ]
        }
      ],
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self, captions, vocab_size=10000):\n",
        "        words = []\n",
        "        for c in captions:\n",
        "            words += re.findall(r\"\\w+\", c.lower())\n",
        "\n",
        "        most_common = Counter(words).most_common(vocab_size - 4)\n",
        "        self.itos = [\"<PAD>\", \"<SOS>\", \"<EOS>\", \"<UNK>\"] + [w for w, _ in most_common]\n",
        "        self.stoi = {w: i for i, w in enumerate(self.itos)}\n",
        "\n",
        "    def encode(self, text):\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            return [self.stoi[\"<SOS>\"], self.stoi[\"<EOS>\"]]\n",
        "        toks = [\"<SOS>\"] + re.findall(r\"\\w+\", text.lower()) + [\"<EOS>\"]\n",
        "        return [self.stoi.get(t, self.stoi[\"<UNK>\"]) for t in toks]\n",
        "\n",
        "    def decode(self, token_list):\n",
        "        words = []\n",
        "        for t in token_list:\n",
        "            if t in (0, 1, 2):  # skip special tokens\n",
        "                continue\n",
        "            if t >= len(self.itos):\n",
        "                words.append(\"<UNK>\")\n",
        "            else:\n",
        "                words.append(self.itos[t])\n",
        "        return \" \".join(words)\n",
        "\n",
        "if len(captions_sample) == 0:\n",
        "    print(\"‚ö†Ô∏è No caption found\")\n",
        "    tokenizer = SimpleTokenizer([\"no event\"], vocab_size=1000)\n",
        "else:\n",
        "    tokenizer = SimpleTokenizer(captions_sample, vocab_size=10000)\n",
        "\n",
        "vocab_size = len(tokenizer.itos)\n",
        "print(f\"üßæ Total Vocabulary: {vocab_size} words\")\n",
        "print(\"üß© Examples :\", tokenizer.itos[:34])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kePlIHhyZXj1",
      "metadata": {
        "id": "kePlIHhyZXj1"
      },
      "source": [
        "###Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5o5ypbxvZWhQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o5ypbxvZWhQ",
        "outputId": "0674d2da-6610-4e51-b674-8a5bd8262b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Size of train_dataset: 300\n",
            "üì¶ Size of val_dataset: 100\n",
            "‚úÖ Batch features shape: torch.Size([4, 5400, 2048])\n",
            "‚úÖ Batch targets shape: torch.Size([4, 11])\n",
            "üí¨ Decoded example : <UNK> <UNK>\n"
          ]
        }
      ],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: list of (features [T_i, D], caption_str)\n",
        "    Retour:\n",
        "      features_padded: [B, max_T, D]\n",
        "      targets_padded:  [B, max_L]\n",
        "    \"\"\"\n",
        "    features_list, token_list = [], []\n",
        "\n",
        "    for feat, cap in batch:\n",
        "        if isinstance(feat, np.ndarray):\n",
        "            feat = torch.from_numpy(feat).float()\n",
        "        features_list.append(feat)\n",
        "        toks = torch.tensor(tokenizer.encode(cap), dtype=torch.long)\n",
        "        token_list.append(toks)\n",
        "\n",
        "    features_padded = pad_sequence(features_list, batch_first=True)\n",
        "    targets_padded = pad_sequence(token_list, batch_first=True, padding_value=tokenizer.stoi[\"<PAD>\"])\n",
        "\n",
        "    return features_padded, targets_padded\n",
        "\n",
        "print(\"üì¶ Size of train_dataset:\", len(train_dataset))\n",
        "print(\"üì¶ Size of val_dataset:\", len(val_dataset))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "batch_features, batch_targets = next(iter(train_loader))\n",
        "print(\"‚úÖ Batch features shape:\", batch_features.shape)\n",
        "print(\"‚úÖ Batch targets shape:\", batch_targets.shape)\n",
        "print(\"üí¨ Decoded example :\", tokenizer.decode(batch_targets[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P7SQ0bxAbmnG",
      "metadata": {
        "id": "P7SQ0bxAbmnG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_KWSnLommwun",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KWSnLommwun",
        "outputId": "6168ca87-b105-4926-9e9a-a98a1d8d7a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [13:45<00:00, 11.00s/it, loss=1.6911]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 1/5 | Train Loss: 1.7508 | Val Loss: 1.0222\n",
            "üíæ New best model saved !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5 [Train]:  27%|‚ñà‚ñà‚ñã       | 20/75 [00:15<00:40,  1.36it/s, loss=1.1235]"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"üöÄ Device:\", device)\n",
        "\n",
        "model = RealTimeVideoCaptionNet(\n",
        "    input_dim=2048,\n",
        "    hidden_dim=512,\n",
        "    vocab_size=vocab_size,\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.AdamW(model.decoder.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 5\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
        "\n",
        "    for features, targets in pbar:\n",
        "        features, targets = features.to(device), targets.to(device)\n",
        "        outputs = model(features)\n",
        "        min_len = min(outputs.size(1), targets.size(1))\n",
        "        outputs = outputs[:, :min_len, :].reshape(-1, vocab_size)\n",
        "        targets = targets[:, :min_len].reshape(-1)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in val_loader:\n",
        "            features, targets = features.to(device), targets.to(device)\n",
        "            outputs = model(features)\n",
        "            min_len = min(outputs.size(1), targets.size(1))\n",
        "            outputs = outputs[:, :min_len, :].reshape(-1, vocab_size)\n",
        "            targets = targets[:, :min_len].reshape(-1)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"‚úÖ Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), \"best_decoder_linformer_gru_soccernet.pth\")\n",
        "        print(\"üíæ New best model saved !\")\n",
        "\n",
        "torch.save(model.state_dict(), \"decoder_linformer_gru_soccernet_final.pth\")\n",
        "print(\"üíæ Final model : decoder_linformer_gru_soccernet_final.pth\")\n",
        "\n",
        "with open(\"tokenizer_vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(tokenizer.itos, f, ensure_ascii=False, indent=2)\n",
        "print(\"üíæ Saved vocabulary : tokenizer_vocab.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_dqGuy4ycQJ1",
      "metadata": {
        "id": "_dqGuy4ycQJ1"
      },
      "source": [
        "### Model and Vocabulary Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "TNKv2tw3O4mO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "TNKv2tw3O4mO",
        "outputId": "88fd7032-ba6a-4953-e419-797927bf08d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Device: cuda\n",
            "üìö Vocabulary is downloaded : 98 words\n",
            "üß© Examples : ['<PAD>', '<SOS>', '<EOS>', '<UNK>', 'by', 'the', 'team', 'at', '2', '1']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for RealTimeVideoCaptionNet:\n\tMissing key(s) in state_dict: \"encoder.proj.0.weight\", \"encoder.proj.0.bias\", \"encoder.proj.1.weight\", \"encoder.proj.1.bias\", \"encoder.temporal_gru.weight_ih_l0\", \"encoder.temporal_gru.weight_hh_l0\", \"encoder.temporal_gru.bias_ih_l0\", \"encoder.temporal_gru.bias_hh_l0\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"decoder.fc.0.weight\", \"decoder.fc.0.bias\", \"decoder.fc.1.weight\", \"decoder.fc.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.proj.weight\", \"encoder.proj.bias\", \"decoder.linformer.net.layers.3.0.fn.proj_k\", \"decoder.linformer.net.layers.3.0.fn.proj_v\", \"decoder.linformer.net.layers.3.0.fn.to_q.weight\", \"decoder.linformer.net.layers.3.0.fn.to_k.weight\", \"decoder.linformer.net.layers.3.0.fn.to_v.weight\", \"decoder.linformer.net.layers.3.0.fn.to_out.weight\", \"decoder.linformer.net.layers.3.0.fn.to_out.bias\", \"decoder.linformer.net.layers.3.0.norm.weight\", \"decoder.linformer.net.layers.3.0.norm.bias\", \"decoder.linformer.net.layers.3.1.fn.w1.weight\", \"decoder.linformer.net.layers.3.1.fn.w1.bias\", \"decoder.linformer.net.layers.3.1.fn.w2.weight\", \"decoder.linformer.net.layers.3.1.fn.w2.bias\", \"decoder.linformer.net.layers.3.1.norm.weight\", \"decoder.linformer.net.layers.3.1.norm.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-746735271.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RealTimeVideoCaptionNet:\n\tMissing key(s) in state_dict: \"encoder.proj.0.weight\", \"encoder.proj.0.bias\", \"encoder.proj.1.weight\", \"encoder.proj.1.bias\", \"encoder.temporal_gru.weight_ih_l0\", \"encoder.temporal_gru.weight_hh_l0\", \"encoder.temporal_gru.bias_ih_l0\", \"encoder.temporal_gru.bias_hh_l0\", \"encoder.norm.weight\", \"encoder.norm.bias\", \"decoder.fc.0.weight\", \"decoder.fc.0.bias\", \"decoder.fc.1.weight\", \"decoder.fc.1.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.proj.weight\", \"encoder.proj.bias\", \"decoder.linformer.net.layers.3.0.fn.proj_k\", \"decoder.linformer.net.layers.3.0.fn.proj_v\", \"decoder.linformer.net.layers.3.0.fn.to_q.weight\", \"decoder.linformer.net.layers.3.0.fn.to_k.weight\", \"decoder.linformer.net.layers.3.0.fn.to_v.weight\", \"decoder.linformer.net.layers.3.0.fn.to_out.weight\", \"decoder.linformer.net.layers.3.0.fn.to_out.bias\", \"decoder.linformer.net.layers.3.0.norm.weight\", \"decoder.linformer.net.layers.3.0.norm.bias\", \"decoder.linformer.net.layers.3.1.fn.w1.weight\", \"decoder.linformer.net.layers.3.1.fn.w1.bias\", \"decoder.linformer.net.layers.3.1.fn.w2.weight\", \"decoder.linformer.net.layers.3.1.fn.w2.bias\", \"decoder.linformer.net.layers.3.1.norm.weight\", \"decoder.linformer.net.layers.3.1.norm.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\". "
          ]
        }
      ],
      "source": [
        "VOCAB_PATH = \"/content/tokenizer_vocab.json\"\n",
        "MODEL_PATH = \"/content/best_decoder_linformer_gru_soccernet.pth\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"üöÄ Device:\", device)\n",
        "\n",
        "model = RealTimeVideoCaptionNet(\n",
        "    input_dim=2048,\n",
        "    hidden_dim=512,\n",
        "    vocab_size=vocab_size,\n",
        ").to(device)\n",
        "\n",
        "if not os.path.exists(VOCAB_PATH):\n",
        "    raise FileNotFoundError(f\"‚ùå Vocabulary not found : {VOCAB_PATH}\")\n",
        "\n",
        "with open(VOCAB_PATH, \"r\") as f:\n",
        "    vocab_data = json.load(f)\n",
        "\n",
        "if isinstance(vocab_data, list):\n",
        "    idx2word = {i: w for i, w in enumerate(vocab_data)}\n",
        "elif isinstance(vocab_data, dict):\n",
        "    if \"idx2word\" in vocab_data:\n",
        "        idx2word = {int(k): v for k, v in vocab_data[\"idx2word\"].items()}\n",
        "    elif all(k.isdigit() for k in vocab_data.keys()):\n",
        "        idx2word = {int(k): v for k, v in vocab_data.items()}\n",
        "    elif \"itos\" in vocab_data:\n",
        "        idx2word = {i: w for i, w in enumerate(vocab_data[\"itos\"])}\n",
        "    elif \"vocab\" in vocab_data:\n",
        "        idx2word = {i: w for i, w in enumerate(vocab_data[\"vocab\"])}\n",
        "    else:\n",
        "        raise ValueError(\"‚ùå Non Recognized Vocabulary Format\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå Unvalid Vocabulary Format\")\n",
        "\n",
        "vocab_size = len(idx2word)\n",
        "print(f\"üìö Vocabulary is downloaded : {vocab_size} words\")\n",
        "print(\"üß© Examples :\", list(idx2word.values())[:10])\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    raise FileNotFoundError(f\"‚ùå Model not found : {MODEL_PATH}\")\n",
        "\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ Model and Vocabulary are successfully selected\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_iRzc_wfQ72C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iRzc_wfQ72C",
        "outputId": "5b8ecc27-7912-424b-d11b-f0f91950cb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Chargement des features depuis : /content/drive/MyDrive/SoccerNetData/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1_ResNET_TF2.npy\n",
            "‚úÖ Features charg√©es : torch.Size([1, 5400, 2048])\n",
            "üìè Nombre de segments : 85\n",
            "\n",
            "üèüÔ∏è Caption g√©n√©r√©e :\n",
            "üó®Ô∏è foul by at 1 throw in by at 1 foul in by at 1 throw by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 ball by at 1 throw by at 1 throw by at 1 throw in by at 1 applicable throw in by at 1 throw by at 1 foul in by at 1 throw in by at 1 foul in by at 1 throw in by at 1 ball by at 1 foul in by at 1 throw in by at 1 ball by at 1 ball by at 1 throw in by at 1 foul in by at 1 ball by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 foul by at 1 throw in by at 1 throw in by at 1 throw by at 1 ball by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 foul in by at 1 ball in by at 1 foul in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 foul by at 1 throw in by at 1 throw by at 1 foul by at 1 foul by at 1 foul in by at 1 foul in by at 1 throw in by at 1 throw in by at 1 foul in by at 1 throw in by at 1 foul by at 1 throw in by at 1 foul in by at 1 throw in by at 1 ball by at 1 foul in by at 1 throw in by at 1 throw in by at 1 throw in by at 1 ball by at 1 throw in by at 1 ball in by at 1 throw by at 1 throw in by at 1 foul in by at 1 foul by at 1 throw in by at 1 foul in by at 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==========================================================\n",
        "# ‚öôÔ∏è Chargement des features\n",
        "# ==========================================================\n",
        "game_path = \"/content/drive/MyDrive/SoccerNetData/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\"\n",
        "feature_path = os.path.join(game_path, \"1_ResNET_TF2.npy\")\n",
        "\n",
        "if not os.path.exists(feature_path):\n",
        "    raise FileNotFoundError(f\"‚ùå Fichier introuvable : {feature_path}\")\n",
        "\n",
        "print(f\"üìÇ Chargement des features depuis : {feature_path}\")\n",
        "\n",
        "features = np.load(feature_path)\n",
        "features = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)  # [1, T, 2048]\n",
        "\n",
        "print(f\"‚úÖ Features charg√©es : {features.shape}\")\n",
        "\n",
        "# ==========================================================\n",
        "# üß© Segmentation en sous-s√©quences\n",
        "# ==========================================================\n",
        "max_len = 64\n",
        "segments = []\n",
        "\n",
        "for i in range(0, features.shape[1], max_len):\n",
        "    seg = features[:, i:i+max_len, :]\n",
        "    # Padding √† la fin si n√©cessaire\n",
        "    if seg.shape[1] < max_len:\n",
        "        pad = torch.zeros(1, max_len - seg.shape[1], features.shape[2]).to(device)\n",
        "        seg = torch.cat([seg, pad], dim=1)\n",
        "    segments.append(seg)\n",
        "\n",
        "print(f\"üìè Nombre de segments : {len(segments)}\")\n",
        "\n",
        "# ==========================================================\n",
        "# üß† Inf√©rence\n",
        "# ==========================================================\n",
        "predicted_tokens = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for seg in segments:\n",
        "        logits = model(seg)  # [1, T, vocab_size]\n",
        "        preds = torch.argmax(logits, dim=-1)  # [1, T]\n",
        "        predicted_tokens.extend(preds.squeeze(0).tolist())\n",
        "\n",
        "# ==========================================================\n",
        "# üó£Ô∏è Reconstruction de la l√©gende\n",
        "# ==========================================================\n",
        "caption_words = [\n",
        "    idx2word.get(t, \"<UNK>\")\n",
        "    for t in predicted_tokens\n",
        "    if t not in [0, 1, 2, 3]  # ignore <PAD>, <SOS>, <EOS>, <UNK>\n",
        "]\n",
        "\n",
        "# Nettoyage simple : √©viter r√©p√©titions directes et tokens vides\n",
        "clean_caption = []\n",
        "for w in caption_words:\n",
        "    if not clean_caption or w != clean_caption[-1]:\n",
        "        clean_caption.append(w)\n",
        "\n",
        "caption_text = \" \".join(clean_caption).replace(\"<UNK>\", \"\").strip()\n",
        "\n",
        "print(\"\\nüèüÔ∏è Caption g√©n√©r√©e :\")\n",
        "print(\"üó®Ô∏è\", caption_text if caption_text else \"(vide ou non d√©codable)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4-wF1VGQPoh5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-wF1VGQPoh5",
        "outputId": "ff17a25b-12ba-42fb-f35d-6ebbe996d667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<PAD>', '<SOS>', '<EOS>', '<UNK>', 'by', 'the', 'team', 'at', '2', '1', 'away', 'home', 'ball', 'out', 'of', 'play', 'not', 'applicable', 'throw', 'in', 'kick', 'shots', 'target', 'foul', 'free', 'clearance', 'indirect', 'off', '00', 'on', 'corner', '24', '05', '04', '29', '25', '39', '03', '41', '35', '10', '43', '16', '34', '42', '09', '37', '27', '13', '14', '40', '11', '20', '02', '30', '22', '28', '21', '19', '01', '31', '08', '15', '17', '23', '12', '06', '33', '36', '18', '26', '44', '38', '32', '07', '45', 'substitution', '47', '46', 'direct', '49', '48', 'card', 'yellow', '51', '55', '53', '57', '59', '52', '58', '56', '50', 'offside', '54', 'goal', 'penalty', 'red']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.itos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iGLgDeCmaNCq",
      "metadata": {
        "id": "iGLgDeCmaNCq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ==========================================================\n",
        "# ‚öôÔ∏è Chargement du mod√®le et du vocabulaire\n",
        "# ==========================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- Charger vocabulaire ---\n",
        "vocab_path = \"/content/tokenizer_vocab.json\"\n",
        "with open(vocab_path, \"r\") as f:\n",
        "    vocab_data = json.load(f)\n",
        "\n",
        "# compatibilit√© : diff√©rents formats possibles\n",
        "if isinstance(vocab_data, dict):\n",
        "    if \"idx2word\" in vocab_data:\n",
        "        idx2word = {int(k): v for k, v in vocab_data[\"idx2word\"].items()}\n",
        "    elif all(isinstance(k, str) for k in vocab_data.keys()):\n",
        "        idx2word = {int(k): v for k, v in vocab_data.items()}\n",
        "    else:\n",
        "        raise ValueError(\"Format de vocab invalide.\")\n",
        "else:\n",
        "    raise ValueError(\"Fichier vocabulaire inattendu.\")\n",
        "\n",
        "vocab_size = len(idx2word)\n",
        "print(f\"üìñ Vocabulaire charg√© ({vocab_size} tokens)\")\n",
        "\n",
        "# --- Charger le mod√®le ---\n",
        "model = RealTimeVideoCaptionNet(\n",
        "    input_dim=2048,\n",
        "    hidden_dim=512,\n",
        "    vocab_size=vocab_size,\n",
        "    reduce_factor=100\n",
        ").to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/best_decoder_linformer_gru_soccernet.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ Mod√®le charg√© et pr√™t pour l‚Äôinf√©rence\")\n",
        "\n",
        "# ==========================================================\n",
        "# ‚öΩ Chargement et r√©duction des features\n",
        "# ==========================================================\n",
        "game_path = \"/content/drive/MyDrive/SoccerNetData/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\"\n",
        "feature_path = os.path.join(game_path, \"1_ResNET_TF2.npy\")\n",
        "\n",
        "print(f\"üìÇ Chargement des features depuis : {feature_path}\")\n",
        "features = np.load(feature_path)\n",
        "features = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(device)  # [1, T, 2048]\n",
        "print(\"‚úÖ Features shape :\", features.shape)\n",
        "\n",
        "# --- R√©duction temporelle dynamique (au lieu de 85 segments s√©par√©s) ---\n",
        "def reduce_features(x, factor=100):\n",
        "    B, T, D = x.shape\n",
        "    T_new = T // factor\n",
        "    x = x[:, :T_new * factor, :]  # d√©coupage propre\n",
        "    x = x.view(B, T_new, factor, D).mean(dim=2)  # moyenne temporelle par bloc\n",
        "    return x\n",
        "\n",
        "reduced_feats = reduce_features(features, factor=64)  # r√©duire ‚âà 64x\n",
        "print(\"üìâ Features r√©duites :\", reduced_feats.shape)\n",
        "\n",
        "# ==========================================================\n",
        "# üß† Pr√©diction avec Top-k Sampling\n",
        "# ==========================================================\n",
        "def top_k_sampling(logits, k=5):\n",
        "    \"\"\"Choisir un token via top-k sampling (plus naturel que argmax).\"\"\"\n",
        "    probs = F.softmax(logits / 1.0, dim=-1)  # temp=1.0\n",
        "    topk_probs, topk_indices = torch.topk(probs, k)\n",
        "    sampled = torch.multinomial(topk_probs, num_samples=1)\n",
        "    next_token = topk_indices.gather(-1, sampled)\n",
        "    return next_token.item()\n",
        "\n",
        "predicted_tokens = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(reduced_feats)  # [1, seq_len, vocab]\n",
        "    for t in range(logits.shape[1]):\n",
        "        token_id = top_k_sampling(logits[0, t], k=5)\n",
        "        predicted_tokens.append(token_id)\n",
        "\n",
        "# ==========================================================\n",
        "# üßπ Nettoyage de la sortie\n",
        "# ==========================================================\n",
        "caption_words = [\n",
        "    idx2word.get(t, \"<UNK>\")\n",
        "    for t in predicted_tokens if t not in [0, 1, 2, 3]\n",
        "]\n",
        "\n",
        "# suppression de r√©p√©titions excessives\n",
        "clean_caption = []\n",
        "for w in caption_words:\n",
        "    if not clean_caption or clean_caption[-1] != w:\n",
        "        clean_caption.append(w)\n",
        "\n",
        "caption_text = \" \".join(clean_caption)\n",
        "caption_text = re.sub(r\"\\s+\", \" \", caption_text).strip()\n",
        "\n",
        "print(\"\\nüèüÔ∏è Caption g√©n√©r√©e :\")\n",
        "print(\"üó®Ô∏è\", caption_text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}